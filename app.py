import os
import json
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv

# ===============================
# í™˜ê²½ ì„¤ì •
# ===============================
load_dotenv()

if not os.environ.get("OPENAI_API_KEY"):
    st.error("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

client = OpenAI(
    base_url="https://gms.ssafy.io/gmsapi/api.openai.com/v1"
)

MEMORY_FILE = "conversation.json"

# ===============================
# ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
# ===============================
def load_conversation():
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return []
    return []

def save_conversation(history):
    try:
        with open(MEMORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    except:
        pass

# ===============================
# ê¸°ì‚¬ ê²€ìƒ‰ ê¸°ëŠ¥ (ì˜ë„ íŒë‹¨ í¬í•¨)
# ===============================
def is_news_request(user_input: str) -> bool:
    keywords = ["ê¸°ì‚¬", "ë‰´ìŠ¤", "ë³´ë„", "ê²€ìƒ‰", "ë‰´ìŠ¤í•´ì¤„", "ê¸°ì‚¬í•´ì¤„"]
    return any(k in user_input for k in keywords)

def get_news_summary(user_input):
    """GPTì—ê²Œ ì§ì ‘ ê¸°ì‚¬ ë‚´ìš© ìš”ì•½ ìš”ì²­"""
    try:
        res = client.chat.completions.create(
            model="gpt-5-nano",
            messages=[
                {
                    "role": "system",
                    "content": "ë„ˆëŠ” ìµœê·¼ ë‰´ìŠ¤ë¥¼ ì •ë¦¬í•´ì„œ ì•Œë ¤ì£¼ëŠ” AIë‹¤. ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì£¼ì œì— ëŒ€í•´ ìµœê·¼ ë‰´ìŠ¤ 3ê°œë¥¼ ê°ê° 3ì¤„ì”© ìš”ì•½í•´ì„œ ë³´ì—¬ì¤˜. í˜•ì‹: [1ë²ˆ] ì œëª©\n3ì¤„ ìš”ì•½\n\n[2ë²ˆ] ì œëª©\n3ì¤„ ìš”ì•½\n\n[3ë²ˆ] ì œëª©\n3ì¤„ ìš”ì•½"
                },
                {
                    "role": "user",
                    "content": f"'{user_input}'ì— ëŒ€í•œ ìµœê·¼ ë‰´ìŠ¤ 3ê°œë¥¼ ê°ê° 3ì¤„ë¡œ ìš”ì•½í•´ì¤„ ìˆ˜ ìˆì–´?"
                }
            ],
            max_completion_tokens=1024,
        )
        return res.choices[0].message.content.strip()
    except Exception as e:
        return f"ê¸°ì‚¬ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ===============================
# ê¸°ë³¸ ì±—ë´‡ ê¸°ëŠ¥
# ===============================
def chatbot_response(history, user_input):
    """ì¼ë°˜ ì±—ë´‡ ì‘ë‹µ ìƒì„± (ë¬¸ë§¥ ìœ ì§€)"""
    messages = [{"role": "system", "content": "ë„ˆëŠ” ì¼ë°˜ì ì¸ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì´ë‹¤. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´."}]
    
    for h in history[-10:]:
        messages.append({"role": h["role"], "content": h["content"]})
    
    messages.append({"role": "user", "content": user_input})

    try:
        res = client.chat.completions.create(
            model="gpt-5-nano",
            messages=messages,
            max_completion_tokens=1024,
        )
        return res.choices[0].message.content.strip()
    except Exception as e:
        return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="AI ì±—ë´‡ + ê¸°ì‚¬ ê²€ìƒ‰", layout="centered")
st.title("í·  AI ì±—ë´‡ + í³° ê¸°ì‚¬ ê²€ìƒ‰")

if "history" not in st.session_state:
    st.session_state.history = load_conversation()

# ì´ì „ ëŒ€í™” ì¶œë ¥
for h in st.session_state.history:
    st.chat_message(h["role"]).write(h["content"])

# ì…ë ¥ì°½
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

if user_input:
    st.chat_message("user").write(user_input)
    st.session_state.history.append({"role": "user", "content": user_input})

    # ê¸°ì‚¬ ê²€ìƒ‰ ì˜ë„ íŒë‹¨
    if is_news_request(user_input):
        response = get_news_summary(user_input)
    else:
        response = chatbot_response(st.session_state.history, user_input)

    st.chat_message("assistant").write(response)
    st.session_state.history.append({"role": "assistant", "content": response})

    # ë¡œì»¬ íŒŒì¼ì— ëŒ€í™” ì €ì¥
    save_conversation(st.session_state.history)
